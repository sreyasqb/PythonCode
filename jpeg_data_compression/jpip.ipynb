{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**JPEG Compression:**\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"markdown","source":"Hello everyone, It's haytamert. This is my initial public kernel to our community. In this kernel I am planning to explain JPEG Compression.  I am not going to implement very important step of the JPEG Compression which is DCT but I will explain how does it work and why we are quantize, recude, reconstruct the image. At the end of the kernel we will understand quantization matrixes for JPEG codec and we can use it for recuding image sizes. Steps of the JPEG compression are listed below: \n\n1. Description of DCT\n2. Reason for Quantization & Quantization Arrays\n3. Block Splitting\n4. Dividing into parts\n5. Discrete Cosine Transform\n6. Inverse Discrete Cosine Transform\n7. Complete the Puzzle\n8. Fourier Comparison of Original Image vs JPEG Compressed Image (Upcoming soon...)\n9. Huffman Coding for More Space (Upcoming soon...)\n10. Results","metadata":{"_uuid":"8c40c740284508999d20e6696446f48ecb6444d3"}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))\n\ndef showImage(img):\n    plt.figure(figsize=(15,15))\n    plt.imshow(img,cmap='gray')\n    plt.xticks([]),plt.yticks([])\n    plt.show()\n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> This is an example code for JPEG image compression. The algorithm behind the JPEG standart comes from Discrete Cosine Transform. A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies. Therefore, an image can be represtented with linear combinations of Discrete Cosine Transform coefficients. \n\n![DCT](https://users.cs.cf.ac.uk/Dave.Marshall/Multimedia/DCT.jpg)\n\n > The DCT transforms an 8×8 block of input values to a linear combination of these 64 patterns. The patterns are referred to as the two-dimensional DCT basis functions, and the output values are referred to as transform coefficients. The top left corner of the transform image represtents lowest frequency, when we move to bottom right corner we are encountering higher frequencies. An image is actually includes most of those frequencies, as I said in first sentence the image can be represtent with linear combinations of those parts of the frequency blocks.","metadata":{"_uuid":"32a21dab1c3c846ec7981231faf7fc5b4e444385"}},{"cell_type":"markdown","source":"**Reason for Quantization & Quantization Arrays**\n>  The human eye is good at seeing small differences in brightness over a relatively large area, but not so good at distinguishing the exact strength of a high frequency brightness variation. This allows one to greatly reduce the amount of information in the high frequency components. This is done by simply dividing each component in the frequency domain by a constant for that component, and then rounding to the nearest integer. This rounding operation is the only lossy operation in the whole process (other than chroma subsampling) if the DCT computation is performed with sufficiently high precision. As a result of this, it is typically the case that many of the higher frequency components are rounded to zero, and many of the rest become small positive or negative numbers, which take many fewer bits to represent.\n\n> Since** DCT coefficient will be divided to quantization arrays elementwise**, the higher value on quantization array will cause higher compression to image. We are expecting to see image size on disk  \n\n> *(Resulted image Q10)<(Resulted image Q50)<(Resulted image Q90).*","metadata":{"_uuid":"a8ad1d4f6345e0034f7ec27f59dbb095ebe3c2f8"}},{"cell_type":"code","source":"#Quantization Arrays\n\ndef selectQMatrix(qName):\n    Q10 = np.array([[80,60,50,80,120,200,255,255],\n                [55,60,70,95,130,255,255,255],\n                [70,65,80,120,200,255,255,255],\n                [70,85,110,145,255,255,255,255],\n                [90,110,185,255,255,255,255,255],\n                [120,175,255,255,255,255,255,255],\n                [245,255,255,255,255,255,255,255],\n                [255,255,255,255,255,255,255,255]])\n\n    Q50 = np.array([[16,11,10,16,24,40,51,61],\n                [12,12,14,19,26,58,60,55],\n                [14,13,16,24,40,57,69,56],\n                [14,17,22,29,51,87,80,62],\n                [18,22,37,56,68,109,103,77],\n                [24,35,55,64,81,104,113,92],\n                [49,64,78,87,103,121,120,101],\n                [72,92,95,98,112,100,130,99]])\n\n    Q90 = np.array([[3,2,2,3,5,8,10,12],\n                    [2,2,3,4,5,12,12,11],\n                    [3,3,3,5,8,11,14,11],\n                    [3,3,4,6,10,17,16,12],\n                    [4,4,7,11,14,22,21,15],\n                    [5,7,11,13,16,12,23,18],\n                    [10,13,16,17,21,24,24,21],\n                    [14,18,19,20,22,20,20,20]])\n    if qName == \"Q10\":\n        return Q10\n    elif qName == \"Q50\":\n        return Q50\n    elif qName == \"Q90\":\n        return Q90\n    else:\n        return np.ones((8,8)) #it suppose to return original image back\n","metadata":{"_uuid":"1105e66c8b6fe145025549bb759abe85ac16c624","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The Original Image**\n> I called showImage function, which is defined above.\n> You can choose between those 4 images which are located in input folder by changing the directory variable.","metadata":{"_uuid":"e12dd936b0f029f116f3637eae14dee43bc90774"}},{"cell_type":"code","source":"directory = 'naturepng.png'\nimg = cv2.imread('../input/'+directory,0)\nshowImage(img)","metadata":{"_uuid":"0d9c45c71d95f22bd7b1a33a9aafa6f9519ac127","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Block Splitting**\n>  Block splitting is one of the processes that splice the image into smaller blocks of 8×8 or a 16×16 dimension. The important thing to understand is why this is done.\n> \n> Assume that we have a 256×256 image. Split these into 1024 8×8 blocks. Now, knowing that the computation complexity for the 2-dimensional DCT operation is O(N^4) and O((N log2N)^2) considering the Fast Cosine Transform, \n> we still have 2564^4 >> (256xlog2256)^2 >> 1024 x (8xlog28 )^2\n> which proves that its advisable to split and perform the operations.\n\n\n>  And the First move is reading image with using OpenCV then, extract height and width of the giving image.  I will be used those variables  for splitting operation.  I am creating an empty list for storing sliced image into 8x8 blocks. \"block\" parameter deciding the block size of sliced image.","metadata":{"_uuid":"13e004ecf0a4c3a3f87f405c492f5acebb7c579e"}},{"cell_type":"code","source":"height  = len(img) #one column of image\nwidth = len(img[0]) # one row of image\nsliced = [] # new list for 8x8 sliced image \nblock = 8\nprint(\"The image heigh is \" +str(height)+\", and image width is \"+str(width)+\" pixels\")","metadata":{"_uuid":"757a667cf893f48956f385196695c47bca0cb193","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dividing into parts**\n> I know it is not the best way to splitting image into small pieces but it works well. Later I am planning to improve these upcoming lines.\n\n> Before computing the DCT of the 8×8 block, its values are shifted from a positive range to one centered on zero. For an 8-bit image, each entry in the original block falls in the range [0,255] . The midpoint of the range (in this case, the value 128) is subtracted from each entry to produce a data range that is centered on zero, so that the modified range is [-128,127] . This step reduces the dynamic range requirements in the DCT processing stage that follows.","metadata":{"_uuid":"c9c8230d32299478e028825be533ff53320debfc"}},{"cell_type":"code","source":"#dividing 8x8 parts\ncurrY = 0 #current Y index\nfor i in range(block,height+1,block):\n    currX = 0 #current X index\n    for j in range(block,width+1,block):\n        sliced.append(img[currY:i,currX:j]-np.ones((8,8))*128) #Extracting 128 from all pixels\n        currX = j\n    currY = i\n    \nprint(\"Size of the sliced image: \"+str(len(sliced)))\nprint(\"Each elemend of sliced list contains a \"+ str(sliced[0].shape)+ \" element.\")\n","metadata":{"_uuid":"50a9b113c39a25ad70351c00260b8466716eefca","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since *cv2.dct* operation requires floating numbers for discrete cosine transform, I am executing a int2float transform here. List comprehension is the easiest way to do so.","metadata":{"_uuid":"07a8ddc52e7e2283b5451dc2b08fc0acf28d3c70"}},{"cell_type":"code","source":"imf = [np.float32(img) for img in sliced]","metadata":{"_uuid":"3e1b0cca5dd3eff418b95965d1e5384b4ee0bd91","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Finally: Discrete Cosine Transform**\n> *cv2.dct* performs a forward or inverse discrete Cosine transform of 1D or 2D array.\n\n> Parameters of  cv2.dct(***input floating-point array***,***output array of the same size and type as source***,***inverse or forward flag***)\n\n> The following lines just calculating the DCT of blocks and append all blocks into *DCToutput*  list.","metadata":{"_uuid":"57c3816055ab7d48d28b1ffaba1053480b836a82"}},{"cell_type":"code","source":"DCToutput = []\nfor part in imf:\n    currDCT = cv2.dct(part)\n    DCToutput.append(currDCT)\nDCToutput[0][0]","metadata":{"_uuid":"b8fce4950d64f0cbaa1210d128b024a0d50cce00","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Again a very very computionaly costy algorithm here. The following code quantize the each pixel in blocks. \n\n> Notice that most of the higher-frequency elements of the sub-block (i.e., those with an x or y spatial frequency greater than 4) are compressed into zero values.\n\n> You can rearrange the Quantization matrix by chancing selectQMatrix input, avaiable Q. Matrix are: \"Q10\", \"Q50\" and \"Q90\". ","metadata":{"_uuid":"d0b13598eb1cf012ff71617a6bd7f459f97a39ac"}},{"cell_type":"code","source":"selectedQMatrix = selectQMatrix(\"Q10\")\nfor ndct in DCToutput:\n    for i in range(block):\n        for j in range(block):\n            ndct[i,j] = np.around(ndct[i,j]/selectedQMatrix[i,j])\nDCToutput[0][0]","metadata":{"_uuid":"2b1d8c3828f3a9418404f5b87b9679bd9c920233","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see quantization is completed. The size has been recuded. Now reconstruct the image back.","metadata":{"_uuid":"abd538eba26ec600776ddbc54b2cbccd03f5aecf"}},{"cell_type":"markdown","source":"**Inverse Discrete Cosine Transform**\n> *cv2.idct()* calculates inverse Discrete Cosine Transform of 1D or 2D array.\n> Parameters of  cv2.idct are same with cv2.dct.","metadata":{"_uuid":"b700e236cb1ef46f639839565f7872d75b762406"}},{"cell_type":"code","source":"invList = []\nfor ipart in DCToutput:\n    ipart\n    curriDCT = cv2.idct(ipart)\n    invList.append(curriDCT)\ninvList[0][0]","metadata":{"_uuid":"fbb818f5bba2d01afdacbf4d87331747a0edf766","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Complete the Puzzle**\n> In the following code, we are putting the image parts together. As we can observe on *invList* is one dimentional list that contains 8x8 numpy arrays inside it. In order to recover the image:\n> 1.  *invList* elements should be parsed at *width/block* steps. For example: If the image width is 1200 pixels, parsing steps should be 1200/8=150 pixels\n> 2. Use *np.hstack* if you are going to recover the image's rows first, else use *np.vstack* for recover columns first.\n> 3. Append all recovered columns into another list.\n> 4. Apply *np.vstack* if you have been used *np.hstack*, reverse order with entry 2.","metadata":{"_uuid":"64ecf9429994392a43e826b3e639a9dc60753cd1"}},{"cell_type":"code","source":"row = 0\nrowNcol = []\nfor j in range(int(width/block),len(invList)+1,int(width/block)):\n    rowNcol.append(np.hstack((invList[row:j])))\n    row = j\nres = np.vstack((rowNcol))","metadata":{"_uuid":"801217e9be95e5b831b70cc0f84fc3cc5afe0693","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Results**\n> There it is, the compressed image. As you can see the image lost some high frequency components and it causes reduced size on disk. There is no change in total pixel count, the JPEG did not reduce the size of the image, it just cancelled out high frequencies.","metadata":{"_uuid":"3b9b6c1cf4bc0c3fe2409e8bdd0ede21139ab43d"}},{"cell_type":"code","source":"showImage(res)","metadata":{"_uuid":"3eb14010d951769e07a5b3e4df3162bc9e8ad32b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"My resources are: \n* Ozyegin University (https://www.ozyegin.edu.tr/en)\n* Hochschule der Median (https://www.hdm-stuttgart.de)\n* Wikipedia (https://en.wikipedia.org/wiki/JPEG)\n","metadata":{"_uuid":"a477f2d28ffcb3b3130b2d30341e13bb6330fd84"}}]}